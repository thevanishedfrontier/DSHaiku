{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:33:15.437147Z",
     "start_time": "2025-02-05T23:33:15.434928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## A. Moore\n",
    "## this notebook was created as an easy and interactive way to upload an image from the user's computer, generate image tags, and utilize deepseek R1 to generate a haiku about said image"
   ],
   "id": "1aa14b2a4f143265",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:18:13.902815Z",
     "start_time": "2025-02-06T00:18:13.894606Z"
    }
   },
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:33:26.517276Z",
     "start_time": "2025-02-05T23:33:24.913069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Importing the tagging model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "## github models is powered by azure\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"DeepSeek-R1\"\n",
    "\n",
    "## add your github token to the environment\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n"
   ],
   "id": "6a1cc94427287196",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T01:25:40.813422Z",
     "start_time": "2025-02-06T01:25:36.560030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Generate the image tags by specifying a file path\n",
    "\n",
    "image = Image.open(\"<file path to image>\").convert(\"RGB\")\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "out = model.generate(**inputs)\n",
    "caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "print(caption)\n"
   ],
   "id": "1ad78b60778b2741",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dog laying on a pillow on a bed\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T01:26:30.965211Z",
     "start_time": "2025-02-06T01:26:03.512280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Pass the image caption to deespseek to generate the haiku\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        UserMessage(content=f\"write a haiku about {caption}\"),\n",
    "    ],\n",
    "    max_tokens=1000,\n",
    "    model=model_name\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "content = response.choices[0].message.content\n",
    "print(content)\n",
    "\n",
    "#Used to remove the text between the think tags i.e. the model \"reasoning\"\n",
    "cleaned_text = re.sub(r\"<think>.*?</think>\", \"\", content, flags=re.DOTALL)\n",
    "\n",
    "#This expression removes the sentence contained after the haiku\n",
    "cleaned_text = re.sub(r\"\\*\", \"\", cleaned_text)\n",
    "\n",
    "# Extract haiku using regex\n",
    "print(cleaned_text)\n"
   ],
   "id": "a03deb1eaed9ab70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sunlit Nap  \n",
      "Golden fur curled tight—  \n",
      "pillow throne cradles soft sighs,  \n",
      "dreams chase sunlit tails.  \n",
      "\n",
      "This haiku uses \"pillow throne\" to elevate the dog's restful moment, while \"sunlit tails\" ties the warmth of the setting to the dog's dreaming mind, blending stillness and subtle motion.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T01:17:13.599771Z",
     "start_time": "2025-02-06T01:17:13.586145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cleaned_text = re.sub(r\"<think>.*?</think>\", \"\", content, flags=re.DOTALL)\n",
    "cleaned_text = re.sub(r\"\\*[^*]*$\", \"\", cleaned_text, flags=re.DOTALL)\n",
    "cleaned_text = re.sub(r\"\\*.*?\", \"\", cleaned_text)\n",
    "print(cleaned_text)"
   ],
   "id": "238470798082e13a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dandelion sun—  \n",
      "man shares silence with his dog,  \n",
      "whispers through the grass.  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
